{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Python scripts with MPI --using mpi4py\n",
    "\n",
    "\n",
    "MPI for Python supports convenient, pickle-based communication of generic Python object as well as fast, near Cspeed, direct array data communication of buffer-provider objects (e.g., NumPy arrays).\n",
    "- Communication of generic Python objects\n",
    "\n",
    "    You have to use all-lowercase methods (of the Comm class), like send(), recv(), bcast(). An object to\n",
    "    be sent is passed as a paramenter to the communication call, and the received object is simply the return value.\n",
    "    \n",
    "    The isend() and irecv() methods return Request instances; completion of these methods can be managed using the test() and wait() methods of the Request class.\n",
    "\n",
    "    The recv() and irecv() methods may be passed a buffer object that can be repeatedly used to receive\n",
    "    messages avoiding internal memory allocation. This buffer must be sufficiently large to accommodate the transmitted messages; hence, any buffer passed to recv() or irecv() must be at least as long as the pickled data\n",
    "    transmitted to the receiver.\n",
    "\n",
    "    Collective calls like scatter(), gather(), allgather(), alltoall() expect a single value or a\n",
    "    sequence of Comm.size elements at the root or all process. They return a single value, a list of Comm.size\n",
    "    elements, or None.\n",
    "\n",
    "- Communication of buffer-like objects\n",
    "    You have to use method names starting with an upper-case letter (of the Comm class), like Send(), Recv(),\n",
    "    Bcast(), Scatter(), Gather().\n",
    "\n",
    "    In general, buffer arguments to these calls must be explicitly specified by using a 2/3-list/tuple like [data,\n",
    "    MPI.DOUBLE], or [data, count, MPI.DOUBLE] (the former one uses the byte-size of data and the\n",
    "    extent of the MPI datatype to define count). \n",
    "\n",
    "## simple example (script.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world from process 0 at UJS.\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "node_name = MPI.Get_processor_name() # get the name of the node\n",
    "\n",
    "print ('Hello world from process %d at %s.' % (rank, node_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Python scripts with MPI, most MPI programs can be run with the command **mpiexec**. In practice, running Python programs looks like:\n",
    "\n",
    "$ mpiexec -n 8 python3 tutorial_mpi4py\n",
    "\n",
    "\n",
    "Hello world from process 1 at UJS.\n",
    "Hello world from process 3 at UJS.\n",
    "Hello world from process 5 at UJS.\n",
    "Hello world from process 6 at UJS.\n",
    "Hello world from process 2 at UJS.\n",
    "Hello world from process 4 at UJS.\n",
    "Hello world from process 7 at UJS.\n",
    "Hello world from process 0 at UJS.\n",
    "\n",
    " **Note that here we use Python3 to run the MPI python script !!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-Point Communication\n",
    "- Python objects (pickle under the hood):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "    print ( 'send data from process %d at %s.' % (rank, data))\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print ( 'Receive data from process %d at %s.' % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "send data from process 0 at {'a': 7, 'b': 3.14}. \n",
    "\n",
    "Recive data from process 1 at {'a': 7, 'b': 3.14}.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python objects with non-blocking communication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "    req = comm.isend(data, dest=1, tag=11)\n",
    "    req.wait()\n",
    "elif rank == 1:\n",
    "    req = comm.irecv(source=0, tag=11)\n",
    "    data = req.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NumPy arrays (the fast way!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# passing MPI datatypes explicitly\n",
    "if rank == 0:\n",
    "    data = numpy.arange(1000, dtype='i')\n",
    "    comm.Send([data, MPI.INT], dest=1, tag=77)\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(1000, dtype='i')\n",
    "    comm.Recv([data, MPI.INT], source=0, tag=77)\n",
    "\n",
    "# automatic MPI datatype discovery\n",
    "if rank == 0:\n",
    "    data = numpy.arange(100, dtype=numpy.float64)\n",
    "    comm.Send(data, dest=1, tag=13)\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(100, dtype=numpy.float64)\n",
    "    comm.Recv(data, source=0, tag=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective Communication\n",
    "- Broadcasting a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'key1' : [7, 2.72, 2+3j],\n",
    "            'key2' : ( 'abc', 'xyz')}\n",
    "else:\n",
    "    data = None\n",
    "data = comm.bcast(data, root=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scattering Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [(i+1)**2 for i in range(size)]\n",
    "else:\n",
    "    data = None\n",
    "data = comm.scatter(data, root=0)\n",
    "assert data == (rank+1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gathering Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "sendbuf = np.zeros(100, dtype='i') + rank\n",
    "recvbuf = None\n",
    "if rank == 0:\n",
    "    recvbuf = np.empty([size, 100], dtype='i')\n",
    "comm.Gather(sendbuf, recvbuf, root=0)\n",
    "if rank == 0:\n",
    "    for i in range(size):\n",
    "        assert np.allclose(recvbuf[i,:], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parallel matrix-vector product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "def matvec(comm, A, x):\n",
    "    m = A.shape[0] # local rows\n",
    "    p = comm.Get_size()\n",
    "    xg = numpy.zeros(m*p, dtype='d')\n",
    "    comm.Allgather([x,  MPI.DOUBLE],\n",
    "                   [xg, MPI.DOUBLE])\n",
    "    y = numpy.dot(A, xg)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI-IO\n",
    "- Collective I/O with NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "amode = MPI.MODE_WRONLY|MPI.MODE_CREATE\n",
    "comm = MPI.COMM_WORLD\n",
    "fh = MPI.File.Open(comm, \"./datafile.contig\", amode)\n",
    "\n",
    "buffer = np.empty(10, dtype=np.int)\n",
    "buffer[:] = comm.Get_rank()\n",
    "\n",
    "offset = comm.Get_rank()*buffer.nbytes\n",
    "fh.Write_at_all(offset, buffer)\n",
    "\n",
    "fh.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non-contiguous Collective I/O with NumPy arrays and datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "amode = MPI.MODE_WRONLY|MPI.MODE_CREATE\n",
    "fh = MPI.File.Open(comm, \"./datafile.noncontig\", amode)\n",
    "\n",
    "item_count = 10\n",
    "\n",
    "buffer = np.empty(item_count, dtype='i')\n",
    "buffer[:] = rank\n",
    "\n",
    "filetype = MPI.INT.Create_vector(item_count, 1, size)\n",
    "filetype.Commit()\n",
    "\n",
    "displacement = MPI.INT.Get_size()*rank\n",
    "fh.Set_view(displacement, filetype=filetype)\n",
    "\n",
    "fh.Write_all(buffer)\n",
    "filetype.Free()\n",
    "fh.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Process Management\n",
    "- Compute Pi - Master (or parent, or client) side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "import sys\n",
    "\n",
    "comm = MPI.COMM_SELF.Spawn(sys.executable,\n",
    "                           args=['cpi.py'],\n",
    "                           maxprocs=5)\n",
    "\n",
    "N = numpy.array(100, 'i')\n",
    "comm.Bcast([N, MPI.INT], root=MPI.ROOT)\n",
    "PI = numpy.array(0.0, 'd')\n",
    "comm.Reduce(None, [PI, MPI.DOUBLE],\n",
    "            op=MPI.SUM, root=MPI.ROOT)\n",
    "print(PI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute Pi - Worker (or child, or server) side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.Comm.Get_parent()\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "N = numpy.array(0, dtype='i')\n",
    "comm.Bcast([N, MPI.INT], root=0)\n",
    "h = 1.0 / N; s = 0.0\n",
    "for i in range(rank, N, size):\n",
    "    x = h * (i + 0.5)\n",
    "    s += 4.0 / (1.0 + x**2)\n",
    "PI = numpy.array(s * h, dtype='d')\n",
    "comm.Reduce([PI, MPI.DOUBLE], None,\n",
    "            op=MPI.SUM, root=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping with SWIG\n",
    "\n",
    " - C source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* file: helloworld.c */\n",
    "void sayhello(MPI_Comm comm)\n",
    "{\n",
    "  int size, rank;\n",
    "  MPI_Comm_size(comm, &size);\n",
    "  MPI_Comm_rank(comm, &rank);\n",
    "  printf(\"Hello, World! \"\n",
    "         \"I am process %d of %d.\\n\",\n",
    "         rank, size);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SWIG interface file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// file: helloworld.i\n",
    "%module helloworld\n",
    "%{\n",
    "#include <mpi.h>\n",
    "#include \"helloworld.c\"\n",
    "}%\n",
    "\n",
    "%include mpi4py/mpi4py.i\n",
    "%mpi4py_typemap(Comm, MPI_Comm);\n",
    "void sayhello(MPI_Comm comm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try it in the Python prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from mpi4py import MPI\n",
    ">>> import helloworld\n",
    ">>> helloworld.sayhello(MPI.COMM_WORLD)\n",
    "Hello, World! I am process 0 of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping with F2Py\n",
    "- Fortran 90 source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! file: helloworld.f90\n",
    "subroutine sayhello(comm)\n",
    "  use mpi\n",
    "  implicit none\n",
    "  integer :: comm, rank, size, ierr\n",
    "  call MPI_Comm_size(comm, size, ierr)\n",
    "  call MPI_Comm_rank(comm, rank, ierr)\n",
    "  print *, 'Hello, World! I am process ',rank,' of ',size,'.'\n",
    "end subroutine sayhello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling example using f2py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ f2py -c --f90exec=mpif90 helloworld.f90 -m helloworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try it in the Python prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from mpi4py import MPI\n",
    ">>> import helloworld\n",
    ">>> fcomm = MPI.COMM_WORLD.py2f()\n",
    ">>> helloworld.sayhello(fcomm)\n",
    "Hello, World! I am process 0 of 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
